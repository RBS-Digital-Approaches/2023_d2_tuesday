{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "funu8olR9nAT"
      },
      "source": [
        "# Mapping MARC records\n",
        "This reader walks through an approach to placing bibliographic records on a map. The main aim of this section is to illustrate using a web API (Application Programming Interface) to retrieve structured data from an online service. As with most things in this domain, though, there are a number of incidental issues that come up along the way that this notebook also illustrates, including:\n",
        "\n",
        "* Working with files;\n",
        "* Cleaning and regularizing data;\n",
        "* Arranging and formatting data for a given purpose.\n",
        "\n",
        "So this notebook aims to be a practical, hands-on illustration of many of the kinds of routine puzzles you'd find yourself handling along the way as you approached a task like this one.\n",
        "\n",
        ">*Note:* For the actual mapping, we will be using the [Bokeh visualization library](https://bokeh.org/). Bokeh is well-suited for this context (i.e., embedding visualizations in Jupyter/Google Colab notebooks), because it allows us to make data produced by Python code available for dynamic filtering in a visualization that's actually produced by JavaScript.\n",
        ">\n",
        "> If you were working on a mapping visualization to be used in a different context (say, as part of a public-facing web site), there are other tools that would probably be better suited for the purpose.\n",
        ">\n",
        ">For that reason, we won't dwell too much on the details of what's going on when we get to the Bokeh code: I'll describe what's happening in general terms, but won't focus too much on explaining Bokeh, specifically, because the details for implementation will vary with different libraries that you might use for the same purpose in other contexts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUpRCaKdJNXh"
      },
      "source": [
        "##1 - Combobulate\n",
        "As always, we need to connect to Google Drive and install some Python packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "w6umRJZ7o3ed"
      },
      "outputs": [],
      "source": [
        "#Code cell 1\n",
        "#Connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAAF52HkpMtE"
      },
      "outputs": [],
      "source": [
        "#Code cell 3\n",
        "#Install the Pymarc package for reading MARC records\n",
        "!pip install pymarc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InbsYZCipwE1"
      },
      "outputs": [],
      "source": [
        "#Code cell 4\n",
        "#Import some packages that we'll need right away:\n",
        "#Pymarc and Regular Expressions (re)\n",
        "from pymarc import MARCReader\n",
        "import re\n",
        "#We'll also immport NumPy (for souped-up numerical work) and Pandas (for working\n",
        "#with DataFrames). Both of these modules are pre-installed in Google Colab. If\n",
        "#you were working in a different environment, you'd need to make sure that these\n",
        "#packages were installed (using, e.g., pip or Anaconda).\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJFnW73Krwcn"
      },
      "outputs": [],
      "source": [
        "#Code cell 5\n",
        "#Information from https://www.loc.gov/marc/countries/. This is a Python\n",
        "#dictionary where each two(-ish) letter country code is a \"key\" and the\n",
        "#corresponding country name is the \"value.\" (So the value of\n",
        "#marc_country_codes['af'] is 'Afghanistan', for example.)\n",
        "marc_country_codes = {\n",
        "    \"aa\": \"Albania\",\n",
        "\"abc\": \"Alberta\",\n",
        "\"-ac\": \"Ashmore and Cartier Islands\",\n",
        "\"aca\": \"Australian Capital Territory\",\n",
        "\"ae\": \"Algeria\",\n",
        "\"af\": \"Afghanistan\",\n",
        "\"ag\": \"Argentina\",\n",
        "\"-ai\": \"Anguilla\",\n",
        "\"ai\": \"Armenia (Republic)\",\n",
        "\"-air\": \"Armenian S.S.R.\",\n",
        "\"aj\": \"Azerbaijan\",\n",
        "\"-ajr\": \"Azerbaijan S.S.R.\",\n",
        "\"aku\": \"Alaska\",\n",
        "\"alu\": \"Alabama\",\n",
        "\"am\": \"Anguilla\",\n",
        "\"an\": \"Andorra\",\n",
        "\"ao\": \"Angola\",\n",
        "\"aq\": \"Antigua and Barbuda\",\n",
        "\"aru\": \"Arkansas\",\n",
        "\"as\": \"American Samoa\",\n",
        "\"at\": \"Australia\",\n",
        "\"au\": \"Austria\",\n",
        "\"aw\": \"Aruba\",\n",
        "\"ay\": \"Antarctica\",\n",
        "\"azu\": \"Arizona\",\n",
        "\"ba\": \"Bahrain\",\n",
        "\"bb\": \"Barbados\",\n",
        "\"bcc\": \"British Columbia\",\n",
        "\"bd\": \"Burundi\",\n",
        "\"be\": \"Belgium\",\n",
        "\"bf\": \"Bahamas\",\n",
        "\"bg\": \"Bangladesh\",\n",
        "\"bh\": \"Belize\",\n",
        "\"bi\": \"British Indian Ocean Territory\",\n",
        "\"bl\": \"Brazil\",\n",
        "\"bm\": \"Bermuda Islands\",\n",
        "\"bn\": \"Bosnia and Herzegovina\",\n",
        "\"bo\": \"Bolivia\",\n",
        "\"bp\": \"Solomon Islands\",\n",
        "\"br\": \"Burma\",\n",
        "\"bs\": \"Botswana\",\n",
        "\"bt\": \"Bhutan\",\n",
        "\"bu\": \"Bulgaria\",\n",
        "\"bv\": \"Bouvet Island\",\n",
        "\"bw\": \"Belarus\",\n",
        "\"-bwr\": \"Byelorussian S.S.R.\",\n",
        "\"bx\": \"Brunei\",\n",
        "\"ca\": \"Caribbean Netherlands\",\n",
        "\"cau\": \"California\",\n",
        "\"cb\": \"Cambodia\",\n",
        "\"cc\": \"China\",\n",
        "\"cd\": \"Chad\",\n",
        "\"ce\": \"Sri Lanka\",\n",
        "\"cf\": \"Congo (Brazzaville)\",\n",
        "\"cg\": \"Congo (Democratic Republic)\",\n",
        "\"ch\": \"China (Republic : 1949- )\",\n",
        "\"ci\": \"Croatia\",\n",
        "\"cj\": \"Cayman Islands\",\n",
        "\"ck\": \"Colombia\",\n",
        "\"cl\": \"Chile\",\n",
        "\"cm\": \"Cameroon\",\n",
        "\"-cn\": \"Canada\",\n",
        "\"co\": \"Curaçao\",\n",
        "\"cou\": \"Colorado\",\n",
        "\"-cp\": \"Canton and Enderbury Islands\",\n",
        "\"cq\": \"Comoros\",\n",
        "\"cr\": \"Costa Rica\",\n",
        "\"-cs\": \"Czechoslovakia\",\n",
        "\"ctu\": \"Connecticut\",\n",
        "\"cu\": \"Cuba\",\n",
        "\"cv\": \"Cabo Verde\",\n",
        "\"cw\": \"Cook Islands\",\n",
        "\"cx\": \"Central African Republic\",\n",
        "\"cy\": \"Cyprus\",\n",
        "\"-cz\": \"Canal Zone\",\n",
        "\"dcu\": \"District of Columbia\",\n",
        "\"deu\": \"Delaware\",\n",
        "\"dk\": \"Denmark\",\n",
        "\"dm\": \"Benin\",\n",
        "\"dq\": \"Dominica\",\n",
        "\"dr\": \"Dominican Republic\",\n",
        "\"ea\": \"Eritrea\",\n",
        "\"ec\": \"Ecuador\",\n",
        "\"eg\": \"Equatorial Guinea\",\n",
        "\"em\": \"Timor-Leste\",\n",
        "\"enk\": \"England\",\n",
        "\"er\": \"Estonia\",\n",
        "\"-err\": \"Estonia\",\n",
        "\"es\": \"El Salvador\",\n",
        "\"et\": \"Ethiopia\",\n",
        "\"fa\": \"Faroe Islands\",\n",
        "\"fg\": \"French Guiana\",\n",
        "\"fi\": \"Finland\",\n",
        "\"fj\": \"Fiji\",\n",
        "\"fk\": \"Falkland Islands\",\n",
        "\"flu\": \"Florida\",\n",
        "\"fm\": \"Micronesia (Federated States)\",\n",
        "\"fp\": \"French Polynesia\",\n",
        "\"fr\": \"France\",\n",
        "\"fs\": \"Terres australes et antarctiques françaises\",\n",
        "\"ft\": \"Djibouti\",\n",
        "\"gau\": \"Georgia\",\n",
        "\"gb\": \"Kiribati\",\n",
        "\"gd\": \"Grenada\",\n",
        "\"-ge\": \"Germany (East)\",\n",
        "\"gg\": \"Guernsey\",\n",
        "\"gh\": \"Ghana\",\n",
        "\"gi\": \"Gibraltar\",\n",
        "\"gl\": \"Greenland\",\n",
        "\"gm\": \"Gambia\",\n",
        "\"-gn\": \"Gilbert and Ellice Islands\",\n",
        "\"go\": \"Gabon\",\n",
        "\"gp\": \"Guadeloupe\",\n",
        "\"gr\": \"Greece\",\n",
        "\"gs\": \"Georgia (Republic)\",\n",
        "\"-gsr\": \"Georgian S.S.R.\",\n",
        "\"gt\": \"Guatemala\",\n",
        "\"gu\": \"Guam\",\n",
        "\"gv\": \"Guinea\",\n",
        "\"gw\": \"Germany\",\n",
        "\"gy\": \"Guyana\",\n",
        "\"gz\": \"Gaza Strip\",\n",
        "\"hiu\": \"Hawaii\",\n",
        "\"-hk\": \"Hong Kong\",\n",
        "\"hm\": \"Heard and McDonald Islands\",\n",
        "\"ho\": \"Honduras\",\n",
        "\"ht\": \"Haiti\",\n",
        "\"hu\": \"Hungary\",\n",
        "\"iau\": \"Iowa\",\n",
        "\"ic\": \"Iceland\",\n",
        "\"idu\": \"Idaho\",\n",
        "\"ie\": \"Ireland\",\n",
        "\"ii\": \"India\",\n",
        "\"ilu\": \"Illinois\",\n",
        "\"im\": \"Isle of Man\",\n",
        "\"inu\": \"Indiana\",\n",
        "\"io\": \"Indonesia\",\n",
        "\"iq\": \"Iraq\",\n",
        "\"ir\": \"Iran\",\n",
        "\"is\": \"Israel\",\n",
        "\"it\": \"Italy\",\n",
        "\"-iu\": \"Israel-Syria Demilitarized Zones\",\n",
        "\"iv\": \"Côte d'Ivoire\",\n",
        "\"-iw\": \"Israel-Jordan Demilitarized Zones\",\n",
        "\"iy\": \"Iraq-Saudi Arabia Neutral Zone\",\n",
        "\"ja\": \"Japan\",\n",
        "\"je\": \"Jersey\",\n",
        "\"ji\": \"Johnston Atoll\",\n",
        "\"jm\": \"Jamaica\",\n",
        "\"-jn\": \"Jan Mayen\",\n",
        "\"jo\": \"Jordan\",\n",
        "\"ke\": \"Kenya\",\n",
        "\"kg\": \"Kyrgyzstan\",\n",
        "\"-kgr\": \"Kirghiz S.S.R.\",\n",
        "\"kn\": \"Korea (North)\",\n",
        "\"ko\": \"Korea (South)\",\n",
        "\"ksu\": \"Kansas\",\n",
        "\"ku\": \"Kuwait\",\n",
        "\"kv\": \"Kosovo\",\n",
        "\"kyu\": \"Kentucky\",\n",
        "\"kz\": \"Kazakhstan\",\n",
        "\"-kzr\": \"Kazakh S.S.R.\",\n",
        "\"lau\": \"Louisiana\",\n",
        "\"lb\": \"Liberia\",\n",
        "\"le\": \"Lebanon\",\n",
        "\"lh\": \"Liechtenstein\",\n",
        "\"li\": \"Lithuania\",\n",
        "\"-lir\": \"Lithuania\",\n",
        "\"-ln\": \"Central and Southern Line Islands\",\n",
        "\"lo\": \"Lesotho\",\n",
        "\"ls\": \"Laos\",\n",
        "\"lu\": \"Luxembourg\",\n",
        "\"lv\": \"Latvia\",\n",
        "\"-lvr\": \"Latvia\",\n",
        "\"ly\": \"Libya\",\n",
        "\"mau\": \"Massachusetts\",\n",
        "\"mbc\": \"Manitoba\",\n",
        "\"mc\": \"Monaco\",\n",
        "\"mdu\": \"Maryland\",\n",
        "\"meu\": \"Maine\",\n",
        "\"mf\": \"Mauritius\",\n",
        "\"mg\": \"Madagascar\",\n",
        "\"-mh\": \"Macao\",\n",
        "\"miu\": \"Michigan\",\n",
        "\"mj\": \"Montserrat\",\n",
        "\"mk\": \"Oman\",\n",
        "\"ml\": \"Mali\",\n",
        "\"mm\": \"Malta\",\n",
        "\"mnu\": \"Minnesota\",\n",
        "\"mo\": \"Montenegro\",\n",
        "\"mou\": \"Missouri\",\n",
        "\"mp\": \"Mongolia\",\n",
        "\"mq\": \"Martinique\",\n",
        "\"mr\": \"Morocco\",\n",
        "\"msu\": \"Mississippi\",\n",
        "\"mtu\": \"Montana\",\n",
        "\"mu\": \"Mauritania\",\n",
        "\"mv\": \"Moldova\",\n",
        "\"-mvr\": \"Moldavian S.S.R.\",\n",
        "\"mw\": \"Malawi\",\n",
        "\"mx\": \"Mexico\",\n",
        "\"my\": \"Malaysia\",\n",
        "\"mz\": \"Mozambique\",\n",
        "\"-na\": \"Netherlands Antilles\",\n",
        "\"nbu\": \"Nebraska\",\n",
        "\"ncu\": \"North Carolina\",\n",
        "\"ndu\": \"North Dakota\",\n",
        "\"ne\": \"Netherlands\",\n",
        "\"nfc\": \"Newfoundland and Labrador\",\n",
        "\"ng\": \"Niger\",\n",
        "\"nhu\": \"New Hampshire\",\n",
        "\"nik\": \"Northern Ireland\",\n",
        "\"nju\": \"New Jersey\",\n",
        "\"nkc\": \"New Brunswick\",\n",
        "\"nl\": \"New Caledonia\",\n",
        "\"-nm\": \"Northern Mariana Islands\",\n",
        "\"nmu\": \"New Mexico\",\n",
        "\"nn\": \"Vanuatu\",\n",
        "\"no\": \"Norway\",\n",
        "\"np\": \"Nepal\",\n",
        "\"nq\": \"Nicaragua\",\n",
        "\"nr\": \"Nigeria\",\n",
        "\"nsc\": \"Nova Scotia\",\n",
        "\"ntc\": \"Northwest Territories\",\n",
        "\"nu\": \"Nauru\",\n",
        "\"nuc\": \"Nunavut\",\n",
        "\"nvu\": \"Nevada\",\n",
        "\"nw\": \"Northern Mariana Islands\",\n",
        "\"nx\": \"Norfolk Island\",\n",
        "\"nyu\": \"New York (State)\",\n",
        "\"nz\": \"New Zealand\",\n",
        "\"ohu\": \"Ohio\",\n",
        "\"oku\": \"Oklahoma\",\n",
        "\"onc\": \"Ontario\",\n",
        "\"oru\": \"Oregon\",\n",
        "\"ot\": \"Mayotte\",\n",
        "\"pau\": \"Pennsylvania\",\n",
        "\"pc\": \"Pitcairn Island\",\n",
        "\"pe\": \"Peru\",\n",
        "\"pf\": \"Paracel Islands\",\n",
        "\"pg\": \"Guinea-Bissau\",\n",
        "\"ph\": \"Philippines\",\n",
        "\"pic\": \"Prince Edward Island\",\n",
        "\"pk\": \"Pakistan\",\n",
        "\"pl\": \"Poland\",\n",
        "\"pn\": \"Panama\",\n",
        "\"po\": \"Portugal\",\n",
        "\"pp\": \"Papua New Guinea\",\n",
        "\"pr\": \"Puerto Rico\",\n",
        "\"-pt\": \"Portuguese Timor\",\n",
        "\"pw\": \"Palau\",\n",
        "\"py\": \"Paraguay\",\n",
        "\"qa\": \"Qatar\",\n",
        "\"qea\": \"Queensland\",\n",
        "\"quc\": \"Québec (Province)\",\n",
        "\"rb\": \"Serbia\",\n",
        "\"re\": \"Réunion\",\n",
        "\"rh\": \"Zimbabwe\",\n",
        "\"riu\": \"Rhode Island\",\n",
        "\"rm\": \"Romania\",\n",
        "\"ru\": \"Russia (Federation)\",\n",
        "\"-rur\": \"Russian S.F.S.R.\",\n",
        "\"rw\": \"Rwanda\",\n",
        "\"-ry\": \"Ryukyu Islands, Southern\",\n",
        "\"sa\": \"South Africa\",\n",
        "\"-sb\": \"Svalbard\",\n",
        "\"sc\": \"Saint-Barthélemy\",\n",
        "\"scu\": \"South Carolina\",\n",
        "\"sd\": \"South Sudan\",\n",
        "\"sdu\": \"South Dakota\",\n",
        "\"se\": \"Seychelles\",\n",
        "\"sf\": \"Sao Tome and Principe\",\n",
        "\"sg\": \"Senegal\",\n",
        "\"sh\": \"Spanish North Africa\",\n",
        "\"si\": \"Singapore\",\n",
        "\"sj\": \"Sudan\",\n",
        "\"-sk\": \"Sikkim\",\n",
        "\"sl\": \"Sierra Leone\",\n",
        "\"sm\": \"San Marino\",\n",
        "\"sn\": \"Sint Maarten\",\n",
        "\"snc\": \"Saskatchewan\",\n",
        "\"so\": \"Somalia\",\n",
        "\"sp\": \"Spain\",\n",
        "\"sq\": \"Eswatini\",\n",
        "\"sr\": \"Surinam\",\n",
        "\"ss\": \"Western Sahara\",\n",
        "\"st\": \"Saint-Martin\",\n",
        "\"stk\": \"Scotland\",\n",
        "\"su\": \"Saudi Arabia\",\n",
        "\"-sv\": \"Swan Islands\",\n",
        "\"sw\": \"Sweden\",\n",
        "\"sx\": \"Namibia\",\n",
        "\"sy\": \"Syria\",\n",
        "\"sz\": \"Switzerland\",\n",
        "\"ta\": \"Tajikistan\",\n",
        "\"-tar\": \"Tajik S.S.R.\",\n",
        "\"tc\": \"Turks and Caicos Islands\",\n",
        "\"tg\": \"Togo\",\n",
        "\"th\": \"Thailand\",\n",
        "\"ti\": \"Tunisia\",\n",
        "\"tk\": \"Turkmenistan\",\n",
        "\"-tkr\": \"Turkmen S.S.R.\",\n",
        "\"tl\": \"Tokelau\",\n",
        "\"tma\": \"Tasmania\",\n",
        "\"tnu\": \"Tennessee\",\n",
        "\"to\": \"Tonga\",\n",
        "\"tr\": \"Trinidad and Tobago\",\n",
        "\"ts\": \"United Arab Emirates\",\n",
        "\"-tt\": \"Trust Territory of the Pacific Islands\",\n",
        "\"tu\": \"Turkey\",\n",
        "\"tv\": \"Tuvalu\",\n",
        "\"txu\": \"Texas\",\n",
        "\"tz\": \"Tanzania\",\n",
        "\"ua\": \"Egypt\",\n",
        "\"uc\": \"United States Misc. Caribbean Islands\",\n",
        "\"ug\": \"Uganda\",\n",
        "\"-ui\": \"United Kingdom Misc. Islands\",\n",
        "\"-uik\": \"United Kingdom Misc. Islands\",\n",
        "\"-uk\": \"United Kingdom\",\n",
        "\"un\": \"Ukraine\",\n",
        "\"-unr\": \"Ukraine\",\n",
        "\"up\": \"United States Misc. Pacific Islands\",\n",
        "\"-ur\": \"Soviet Union\",\n",
        "\"-us\": \"United States\",\n",
        "\"utu\": \"Utah\",\n",
        "\"uv\": \"Burkina Faso\",\n",
        "\"uy\": \"Uruguay\",\n",
        "\"uz\": \"Uzbekistan\",\n",
        "\"-uzr\": \"Uzbek S.S.R.\",\n",
        "\"vau\": \"Virginia\",\n",
        "\"vb\": \"British Virgin Islands\",\n",
        "\"vc\": \"Vatican City\",\n",
        "\"ve\": \"Venezuela\",\n",
        "\"vi\": \"Virgin Islands of the United States\",\n",
        "\"vm\": \"Vietnam\",\n",
        "\"-vn\": \"Vietnam, North\",\n",
        "\"vp\": \"Various places\",\n",
        "\"vra\": \"Victoria\",\n",
        "\"-vs\": \"Vietnam, South\",\n",
        "\"vtu\": \"Vermont\",\n",
        "\"wau\": \"Washington (State)\",\n",
        "\"-wb\": \"West Berlin\",\n",
        "\"wea\": \"Western Australia\",\n",
        "\"wf\": \"Wallis and Futuna\",\n",
        "\"wiu\": \"Wisconsin\",\n",
        "\"wj\": \"West Bank of the Jordan River\",\n",
        "\"wk\": \"Wake Island\",\n",
        "\"wlk\": \"Wales\",\n",
        "\"ws\": \"Samoa\",\n",
        "\"wvu\": \"West Virginia\",\n",
        "\"wyu\": \"Wyoming\",\n",
        "\"xa\": \"Christmas Island (Indian Ocean)\",\n",
        "\"xb\": \"Cocos (Keeling) Islands\",\n",
        "\"xc\": \"Maldives\",\n",
        "\"xd\": \"Saint Kitts-Nevis\",\n",
        "\"xe\": \"Marshall Islands\",\n",
        "\"xf\": \"Midway Islands\",\n",
        "\"xga\": \"Coral Sea Islands Territory\",\n",
        "\"xh\": \"Niue\",\n",
        "\"-xi\": \"Saint Kitts-Nevis-Anguilla\",\n",
        "\"xj\": \"Saint Helena\",\n",
        "\"xk\": \"Saint Lucia\",\n",
        "\"xl\": \"Saint Pierre and Miquelon\",\n",
        "\"xm\": \"Saint Vincent and the Grenadines\",\n",
        "\"xn\": \"North Macedonia\",\n",
        "\"xna\": \"New South Wales\",\n",
        "\"xo\": \"Slovakia\",\n",
        "\"xoa\": \"Northern Territory\",\n",
        "\"xp\": \"Spratly Island\",\n",
        "\"xr\": \"Czech Republic\",\n",
        "\"xra\": \"South Australia\",\n",
        "\"xs\": \"South Georgia and the South Sandwich Islands\",\n",
        "\"xv\": \"Slovenia\",\n",
        "\"xx\": \"No place, unknown, or undetermined\",\n",
        "\"xxc\": \"Canada\",\n",
        "\"xxk\": \"United Kingdom\",\n",
        "\"-xxr\": \"Soviet Union\",\n",
        "\"xxu\": \"United States\",\n",
        "\"ye\": \"Yemen\",\n",
        "\"ykc\": \"Yukon Territory\",\n",
        "\"-ys\": \"Yemen (People's Democratic Republic)\",\n",
        "\"-yu\": \"Serbia and Montenegro\",\n",
        "\"za\": \"Zambia\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTvEqapcpTF1"
      },
      "outputs": [],
      "source": [
        "#Code cell 6\n",
        "#Create a variable with the path to our data folder\n",
        "source_directory = '/gdrive/MyDrive/rbs_digital_approaches_2023/2023_data_class/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5migC7dXzK7"
      },
      "source": [
        "##A sidenote on a Unicode niggle...\n",
        "In the course of updating this notebook I ran into a strange error I hadn't encountered before when working with the same MARC records. After (quite) some time troubleshooting, I realized that the issue was arising because I was doing some work with the MARC data directly in Python code, rather than massaging the MARC data in OpenRefine and Google Sheets first, as I had done in a different iteration.\n",
        "\n",
        "This sort of thing can be maddening to diagnose, so I wanted to remark on it here.\n",
        "\n",
        "The problem turned out to lie in the way that combining diacritics were handled in Unicode. One of the publication places in this batch of records is in Welsh and contains the character \"ŷ\". As I was reminded, Unicode offers multiple ways to represent a character like that one. While \"ŷ\" is defined in Unicode as \"Latin small letter y with circumflex\" at Unicode point U+0177, it's also possible to create \"ŷ\" by combining \"y\" (\"Latin small letter y\": U+0079) with \" ̂\" (\"Combining circumflex accent\": U+0302).\n",
        "\n",
        "When I was working with the file in a text editor, my text editor was representing (and saving) \"ŷ\" as U+0177; but it turned out that, in the original file, \"ŷ\" was being constructed with a lower-case \"y\" and the combining circumflex. When printed to screen, the combination of U+0079 and U+0302 is visually indistinguishable from U+0177. But the code is dealing with the characters, not their visual presentation, and that led to some completely baffling results, as in code cell 7.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8KTDXP_Jji4"
      },
      "outputs": [],
      "source": [
        "#Code cell 7\n",
        "#Just to demonstrate the problem...\n",
        "\n",
        "#Open the file of MARC records in binary mode with Pymarc's MARCReader\n",
        "reader = MARCReader(open(source_directory + '2023_d1_estc_pilgrims_progress.mrc', 'rb'))\n",
        "\n",
        "#Create an empty variable to catch the problem city\n",
        "problem_city = ''\n",
        "\n",
        "#Loop through the MARC records\n",
        "for record in reader :\n",
        "  #Create a variable for the contents of MARC field 260$a (publication place)\n",
        "  pub_city = record['260']['a']\n",
        "  #Look for a publication cirt beginning with the letters \"Arg\"\n",
        "  if re.search(r'^Arg.+', pub_city) is not None :\n",
        "    #Print the publication city as it appears in the record\n",
        "    print('From line 17; ' + pub_city)\n",
        "    #Assign this pub_city as the value of the heretofore-empty problem_city variable\n",
        "    problem_city = pub_city\n",
        "\n",
        "#Check to see if the value of problem_city matches the string that was printed\n",
        "#to screen back at line 16\n",
        "if problem_city == 'Argraphwŷd yn y Mwŷthig :' :\n",
        "  print('From lines 23-6: \"' + problem_city + '\" matches \"Argraphwŷd yn y Mwŷthig :\"')\n",
        "else :\n",
        "  print('From lines 23-6: \"' + problem_city + '\" does not match \"Argraphwŷd yn y Mwŷthig :\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpcW6P_GKx_y"
      },
      "outputs": [],
      "source": [
        "#Code cell 8\n",
        "#Create a list of integers representing the Unicode code point of each character\n",
        "#in the string \"Argraphwŷd yn y Mwŷthig :\" (which was printed to screen at line\n",
        "#16 of the previous cell) and print the length of that list\n",
        "appearance = [ord(i) for i in 'Argraphwŷd yn y Mwŷthig :']\n",
        "print(len(appearance))\n",
        "\n",
        "#Create a similar list for the characters of the value stored in the problem_city\n",
        "#variable and print out its length.\n",
        "reality = [ord(j) for j in problem_city]\n",
        "print(len(reality))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLz_oFYRFBPh"
      },
      "outputs": [],
      "source": [
        "#Code cell 9\n",
        "#For each integer in the list of code points for the characters in the problem_city\n",
        "#variable, print the integer and the corresponding Unicode character\n",
        "for char in reality :\n",
        "  print(str(char) + ': ' + chr(char))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsQBPLOenqKD"
      },
      "outputs": [],
      "source": [
        "#Code cell 10\n",
        "#Import the unicodedata module\n",
        "import unicodedata\n",
        "\n",
        "#Normalize the problem_city variable, first decomposing the Unicode string and then\n",
        "#recomposing it in canonical order.\n",
        "#See https://docs.python.org/3.8/library/unicodedata.html#unicodedata.normalize\n",
        "unicode_normalized_pub_city = unicodedata.normalize('NFC', problem_city)\n",
        "print('From line 9: ' + unicode_normalized_pub_city)\n",
        "if unicode_normalized_pub_city == 'Argraphwŷd yn y Mwŷthig :' :\n",
        "  print('From lines 10-13: \"' + unicode_normalized_pub_city + '\" matches \"Argraphwŷd yn y Mwŷthig :\"')\n",
        "else :\n",
        "  print('From lines 10-13: \"' + unicode_normalized_pub_city + '\" does not match \"Argraphwŷd yn y Mwŷthig :\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N25mgHqBc5NC"
      },
      "source": [
        "##2 - Moving on...\n",
        "Okay, back to actually reading MARC records with Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmYuqQzIU9ca"
      },
      "outputs": [],
      "source": [
        "#Code cell 11\n",
        "#In case you skipped over the sidenote on the Unicode challenge raised by this file...\n",
        "import unicodedata\n",
        "\n",
        "#Create an empty dataframe (basically a spreadsheet) to hold our data\n",
        "bib_records = pd.DataFrame()\n",
        "\n",
        "#Define a couple of regular expressions for stripping away punctuation that's\n",
        "#included in the MARC fields:\n",
        "#1) One or more spaces and/or colons at the end of the string\n",
        "field_punctuation = re.compile(r'[\\s\\:]+$')\n",
        "#2) Opening and closing square brackets, question mark, period, and comma\n",
        "other_punctuation = re.compile(r'[\\[\\]\\?\\.,]')\n",
        "\n",
        "#Open the file of MARC records in binary mode using MARCReader\n",
        "reader = MARCReader(open(source_directory + '2023_d1_estc_pilgrims_progress.mrc', 'rb'))\n",
        "\n",
        "#Loop through the records in the file\n",
        "for record in reader :\n",
        "  #Get the ESTC number from the 001 field\n",
        "  estc_num = record['001'].data\n",
        "\n",
        "  #Get the publication date from the 008 field\n",
        "  pub_year = record['008'].data[7:11]\n",
        "\n",
        "  #Get the publication city from MARC field 260|a using our unicodedata.normalize\n",
        "  #trick\n",
        "  pub_city = unicodedata.normalize('NFC', record['260']['a'])\n",
        "\n",
        "  #Get rid of punctuation that's included in accord with cataloging rules\n",
        "  #using the regular expression defined at line 13, above\n",
        "  stripped_city = re.sub(field_punctuation, '', pub_city)\n",
        "\n",
        "  #If the publication city has \"i.e.\" in it\n",
        "  if stripped_city.find('i.e.') != -1 :\n",
        "    #Only keep the string starting 5 characters ahead of the i in \"i.e.\"\n",
        "    stripped_city = stripped_city[stripped_city.find('i.e.')+5:]\n",
        "\n",
        "  #Remove any other punctuation (like square brackets) from the publication\n",
        "  #city, using the regular expression defined at line 15, above\n",
        "  stripped_city = re.sub(other_punctuation, '', stripped_city)\n",
        "\n",
        "  #Get the country code from MARC field 008, stripping any white space from\n",
        "  #the right: some country codes are three characters long, others are only\n",
        "  #two, and would bring white space with them\n",
        "  country_code = record['008'].data[15:18].rstrip()\n",
        "\n",
        "  #Use the country code as the key to get the corresponding value from the\n",
        "  #marc_country_codes dictionary from code cell 5\n",
        "  country = marc_country_codes[country_code]\n",
        "\n",
        "  #Combine the city name (stripped of punctuation and white space) and the country\n",
        "  orig_place = stripped_city + ' ' + country\n",
        "\n",
        "  #Get the imprint statement\n",
        "  #There seems to have been a change in PyMarc that made some of my code break.\n",
        "  #Syntax for testing for presence of subfield is from here:\n",
        "  #https://groups.google.com/g/pymarc/c/f5A8m0976jY/m/s9dR9yc2AwAJ\n",
        "  if record['260'] :\n",
        "     if record.get('260', {}).get('b', None) is not None :\n",
        "      imprint = record['260']['a'].rstrip(' :') + ': '\n",
        "      imprint += record['260']['b'].rstrip(',')\n",
        "      imprint += ' (' + str(pub_year) + ')'\n",
        "  else :\n",
        "    imprint = ''\n",
        "\n",
        "  #Create a dictionary of the information we've extracted from this records\n",
        "  row_df = pd.DataFrame({'estc_num': estc_num,\n",
        "                         'pub_year': pub_year,\n",
        "                         'imprint': imprint,\n",
        "                         'orig_place': orig_place}, index=[0])\n",
        "  #Update the bib_records dataframe by appending the row we just created, allowing\n",
        "  #pandas to create an index number for the new row\n",
        "  bib_records = pd.concat([bib_records, row_df], ignore_index=True)\n",
        "\n",
        "#Print the dataframe to screen\n",
        "bib_records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFRQ5a2boQDP"
      },
      "source": [
        "## 3 - Regularizing place names\n",
        "In order to find the coordinates for the publication places, we need to make sure that our place names take a form that is likely to be found in the GeoNames database. That can involve modernizing, regularizing, and—in some cases—correcting the information that appears in the catalogue records.\n",
        "\n",
        "In practice, especially with large datasets, I find that it's often easiest to do this kind of work using a tool like [OpenRefine](https://openrefine.org): I can work iteratively and see what's happening at each step along the way.\n",
        "\n",
        "In this case, though, there are really few enough places that we can get our heads around the data cleaning that needs to happen right here in the notebook.\n",
        "\n",
        "We'll start by creating a new DataFrame with the distinct values from the `orig_place` column (there are only 35 of them)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2B1EvFh4H4a"
      },
      "outputs": [],
      "source": [
        "#Code cell 12\n",
        "#Create a new DataFrame of the unique values of the orig_place column of our\n",
        "#existing bib_records DataFrame\n",
        "places = pd.DataFrame(sorted(list(bib_records.orig_place.unique())))\n",
        "places.columns = ['orig_place']\n",
        "places"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMo8MOJC4jDw"
      },
      "source": [
        "Some of these we probably feel confident about how to regularize. Others probably require some scrutiny and research.\n",
        "\n",
        "Figuring out that \"Argraphwŷd yn y Mwŷthig\" involved a Welsh name for Shrewsbury took me some Googling, for instance. I also learned a couple of years ago that there is more than one \"Germantown\" in Pennsylvania (which seems frankly unnecessary, if you ask me). Further investigation into early American printers leaves me pretty confident that the printers listed in the imprints from \"Germantaun\" and \"Germanton\" were based in the Germantown section of Philadelphia.\n",
        "\n",
        "Once that research is done, though, it's not too difficult to map the regularized place names to the forms that appear in the records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXs8L0vY4gGJ"
      },
      "outputs": [],
      "source": [
        "#Code cell 13\n",
        "#This is a Python dictionary with the original place names serving as keys and\n",
        "#the regularized place names serving as the values.\n",
        "regularized_places = {\n",
        "  'Bath England': 'Bath GB',\n",
        "  'Argraphwŷd yn y Mwŷthig England': 'Shrewsbury GB',\n",
        "  'Birmingham England': 'Birmingham GB',\n",
        "  'Boston United States': 'Boston MA USA',\n",
        "  'Boston NE United States': 'Boston MA USA',\n",
        "  'Boston in New-England United States': 'Boston MA USA',\n",
        "  'Bristol England': 'Bristol GB',\n",
        "  'Caerfyrddin Wales': 'Carmarthen GB',\n",
        "  'Caerlleon England': 'Chester GB',\n",
        "  'Coventry England': 'Coventry GB',\n",
        "  'Dublin Ireland': 'Dublin IE',\n",
        "  'Edinburgh England': 'Edinburgh GB',\n",
        "  'Edinburgh Scotland': 'Edinburgh GB',\n",
        "  'Ephrata in Pennsylvania United States': 'Ephrata PA USA',\n",
        "  'Gainsborough England': 'Gainsborough Lincolnshire GB',\n",
        "  'Gainsbrough England': 'Gainsborough Lincolnshire GB',\n",
        "  'Germantaun Pa United States': 'Germantown Philadelphia PA USA',\n",
        "  'Germanton Pa United States': 'Germantown Philadelphia PA USA',\n",
        "  'Glasgow Scotland': 'Glasgow GB',\n",
        "  'Liverpool England': 'Liverpool GB',\n",
        "  'London England': 'London GB',\n",
        "  'Manchester England': 'Manchester GB',\n",
        "  'New-York United States': 'New York NY USA',\n",
        "  'Newcastle England': 'Newcastle upon Tyne GB',\n",
        "  'Newcastle upon Tyne England': 'Newcastle upon Tyne GB',\n",
        "  'Nottingham England': 'Nottingham GB',\n",
        "  'Paisley Scotland': 'Paisley GB',\n",
        "  'Philadelphia United States': 'Philadelphia PA USA',\n",
        "  'Preston England': 'Preston GB',\n",
        "  'Shrewsbury England': 'Shrewsbury GB',\n",
        "  'Vepery India': 'Vepery India',\n",
        "  'Wolverhampton England': 'Wolverhampton GB',\n",
        "  'Worcester United States': 'Worcester MA USA',\n",
        "  'Worcester Mass United States': 'Worcester MA USA',\n",
        "  'York England': 'York GB'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIj4Biyv67Vg"
      },
      "source": [
        "We use this dictionary to add a new column to our `places` DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAksqu0y7C8V"
      },
      "outputs": [],
      "source": [
        "#Code cell 14\n",
        "places['regularized_place'] = places['orig_place'].map(regularized_places)\n",
        "places"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hN1k79U7Hm9"
      },
      "source": [
        "And then we create a new DataFrame that maps our regularized place names to the original place names. This code merges information from the `bib_records` DataFrame with information from the `places` DataFrame: it will have all the columns from the `bib_records` DataFrame plus a `regularized_place` column with values drawn from from the `places` DataFrame. Because both DataFrames have a column labeled `orig_place`, we can use the values in that column to stitch the two DataFrames together: every row in the `beb_recvords` DataFrame that has, say, \"London England\" in the `orig_place` column will have the corresponding regularized form (\"London GB\") found in the `places` DataFrame in the `regularized_place` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VxbmrGt7O4w"
      },
      "outputs": [],
      "source": [
        "#Code cell 15\n",
        "regularized_bib_records = pd.merge(\n",
        "    left=bib_records,\n",
        "    right=places,\n",
        "    on='orig_place',\n",
        "    how='right'\n",
        ")\n",
        "regularized_bib_records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtCDzN4XH1u3"
      },
      "source": [
        "##4 - Get distinct places\n",
        "Now that we have our regularized place names, we're going to get all of the distinct place names (i.e., all of the unique values from the `regularized_place_name` column) so that we only have to look up each place once: there's no need to ask the GeoNames database,\n",
        "\n",
        "\"Where is London GB?\"\n",
        "\n",
        "\"Where is London GB?\"\n",
        "\n",
        "\"Where is London GB?\"\n",
        "\n",
        "(and so on)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awuD3n_VqhOM"
      },
      "outputs": [],
      "source": [
        "#Code cell 16\n",
        "#Create a new dataframe to hold the unique values (i.e., the distinct place names)\n",
        "#in the regularized_place column of the regularized_bib_records dataframe.\n",
        "distinct_places = pd.DataFrame(list(regularized_bib_records.regularized_place.unique()))\n",
        "#Add a column heading to our column\n",
        "distinct_places.columns = ['regularized_place']\n",
        "distinct_places"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaZtzY_oIChL"
      },
      "source": [
        "##5 - Retrieve coordinates from GeoNames API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYxVH_Xjs4u7"
      },
      "outputs": [],
      "source": [
        "#Code cell 17\n",
        "#Time to get our coordinates...\n",
        "\n",
        "#Import a few more modules we'll need to send requests to the GeoNames API\n",
        "#and to parse the JSON data we get back. We're going to talk about this kind of\n",
        "#thing more on Tuesday.\n",
        "import requests\n",
        "import urllib\n",
        "import json\n",
        "import time\n",
        "\n",
        "#We need to write a function to handle requesting information from GeoNames.\n",
        "#We'll end up passing the contents of each of our distinct place names to this\n",
        "#function later\n",
        "def get_coords(placename) :\n",
        "  #The query URL will have the placename in the middle, so we need to construct\n",
        "  #the URL in pieces\n",
        "  #I'll let you know this username in our class session. I don't really want to\n",
        "  #push it to GitHub. You can also set up your own free account and get a username\n",
        "  #of your own. Running this cell without a value for the api_username variable\n",
        "  #will result in an error.\n",
        "  api_username = 'RBSDigitalApproaches'\n",
        "  query_url = 'http://api.geonames.org/search?q='\n",
        "  query_url += placename.replace(' ', '%20')\n",
        "  query_url += '&maxRows=1&type=json&username=' + api_username\n",
        "  #Let's see what the query URL looks like--just because\n",
        "  print(query_url)\n",
        "\n",
        "  #Use the requests module to retrieve the information from our query_url\n",
        "  r = requests.get(query_url)\n",
        "  #Printing the place we're searching for to screen so we know something's\n",
        "  #happening...\n",
        "  print(placename)\n",
        "\n",
        "  #Parse the response from the GeoNames server as json, get the latitude and\n",
        "  #longitude values from the JSON, then combine them into a single string, joined\n",
        "  #by a comma\n",
        "  response = r.json()\n",
        "  lat = float(response['geonames'][0]['lat'])\n",
        "  lng = float(response['geonames'][0]['lng'])\n",
        "\n",
        "  #Print the coordinates, so we know something's happening\n",
        "  print('... ' + str(lat) + ',' + str(lng))\n",
        "\n",
        "  #Pause for two seconds to avoid hammering the GeoNames server. It's only polite.\n",
        "  time.sleep(2)\n",
        "\n",
        "  #The output of the function: this is what we'll get back for the value in each\n",
        "  #row of the distinct_places dataframe\n",
        "  return (lat, lng)\n",
        "\n",
        "#Add a new column to our dataframe with the heading coords. For each row, the\n",
        "#content of that new column is generated by applying the get_coords function that\n",
        "#we just defined to the contents of the existing regularized_place column.\n",
        "distinct_places['coords'] = distinct_places['regularized_place'].apply(get_coords)\n",
        "\n",
        "#Show our updated dataframe\n",
        "distinct_places"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uql0X5fzIc8g"
      },
      "source": [
        "\n",
        "###5.a - If something goes wrong with GeoNames...\n",
        "If you're unable to retrieve the coordinates from GeoNames for any reason, you can run the code in the next cell, then carry on from Code cell 18. If your calls to the GeoNames API are successful, though, you can skip this next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTQSWGEv-v8B"
      },
      "outputs": [],
      "source": [
        "#If you're unable to get the coordinates from GeoNames for any reason, they're\n",
        "#available here. Run this cell, then carry on.\n",
        "emergency_placenames = ['London GB', 'Dublin IE', 'Gainsborough Lincolnshire GB', 'Glasgow GB',\n",
        " 'Edinburgh GB', 'Shrewsbury GB', 'Carmarthen GB', 'Nottingham GB', 'Wolverhampton GB',\n",
        " 'Birmingham GB', 'Coventry GB', 'Manchester GB', 'Preston GB', 'York GB',\n",
        " 'Vepery India', 'Bath GB', 'Newcastle upon Tyne GB', 'Bristol GB', 'New York NY USA',\n",
        " 'Worcester MA USA', 'Boston MA USA', 'Philadelphia PA USA', 'Ephrata PA USA',\n",
        " 'Germantown Philadelphia PA USA', 'Chester GB', 'Paisley GB', 'Liverpool GB']\n",
        "emergency_coordinates = [(51.50853, -0.12574), (53.33306, -6.24889),\n",
        " (53.38333, -0.76667), (55.86515, -4.25763), (55.95206, -3.19648),\n",
        " (52.71009, -2.75208), (51.85552, -4.30535), (52.9536, -1.15047),\n",
        " (52.58547, -2.12296), (52.48142, -1.89983), (52.40656, -1.51217),\n",
        " (53.45, -2.23333), (53.76282, -2.70452), (53.95763, -1.08271),\n",
        " (13.08472, 80.2675), (51.3751, -2.36172), (54.97328, -1.61396),\n",
        " (51.45523, -2.59665), (40.71427, -74.00597), (42.26259, -71.80229),\n",
        " (42.35843, -71.05977), (39.95238, -75.16362), (40.17982, -76.17884),\n",
        " (40.04344, -75.18018), (53.1905, -2.89189), (55.83173, -4.43254),\n",
        " (53.41058, -2.97794)]\n",
        "zipped = list(zip(emergency_placenames, emergency_coordinates))\n",
        "\n",
        "distinct_places = pd.DataFrame(zipped, columns=['regularized_place', 'coords'])\n",
        "distinct_places"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYOoZxm1I33y"
      },
      "source": [
        "##6 - Add coordinates to records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxLAOmGlwRUp"
      },
      "outputs": [],
      "source": [
        "#Code cell 18\n",
        "#Now lets add the coordinates we just got. We do this in the same way we added\n",
        "#the regularized_place column in Code cell 15, but this time we join the\n",
        "#DataFrames on the 'regularized_place' column\n",
        "regularized_bib_records = pd.merge(\n",
        "    left = regularized_bib_records,\n",
        "    right = distinct_places,\n",
        "    on = 'regularized_place',\n",
        "    how = 'right'\n",
        ")\n",
        "regularized_bib_records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRgSaj6eyBsI"
      },
      "outputs": [],
      "source": [
        "#Code cell 19\n",
        "#Transform the values in the pub_year column into integers.\n",
        "#We want to be able to filter by publication year later, and we'll want to be\n",
        "#working with numbers, not strings.\n",
        "regularized_bib_records['pub_year'] = regularized_bib_records['pub_year'].astype(int)\n",
        "\n",
        "#We also want our bibliographic records to appear in chronological order when\n",
        "#they pop up on the map. One easy fix is to just sort them by date here.\n",
        "regularized_bib_records.sort_values(by=['pub_year'], inplace=True)\n",
        "# regularized_bib_records = regularized_bib_records.reset_index()\n",
        "regularized_bib_records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csYSpuoRvebg"
      },
      "source": [
        "##7 - Placing those coordinates on a map\n",
        "We've actually accomplished the main aim of this unit already: getting publication cities, regularizing them, and retrieving coordinates from an API. But to actually see them on a map takes some more doing.\n",
        "\n",
        "There are *lots* of different ways to implement this \"last mile,\" depending on the context. There's a lot more code in this notebook, but most of it is peculiar to this particular context: trying to display Python data on a map generated using a Javascript library, all within a Google Colab notebook. If you were trying to generate maps for a web site, there are other tools that would probably make more sense.\n",
        "\n",
        "So that's just to say that it's probably not worth dwelling for too long on the code that follows unless you happen to be trying to do exactly this. If you're trying to do something else, the implementation details are inevitably going to be different, and you can figure them out when you come to them. In the meantime, we can just click through these next cells quickly in order to assure ourselves that it really did work."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m9RIIhiUIXF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOErUCZHGGJa"
      },
      "outputs": [],
      "source": [
        "#Code cell 20\n",
        "#Install two packages for mapping: Bokeh is a very large and powerful visualization\n",
        "#library that includes mapping among its capabilities. Xyzservices makes it\n",
        "#easy to use a variety of map tiles made available in the widely-used xyz format.\n",
        "\n",
        "#We need a newer version of Bokeh than is installed in Colab by default at\n",
        "#this time. Note one warning we get about the installed version of panel not\n",
        "#being compatible with this vesion of Bokeh. As it happens, we're not using panel.\n",
        "#If we were, though, we'd need to upgrade that, as well—and possibly some other\n",
        "#things.\n",
        "!pip install bokeh==2.4.3\n",
        "!pip install xyzservices"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xyzservices"
      ],
      "metadata": {
        "id": "CdUg9mxUIZ8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UwhtJ6ECaNq"
      },
      "outputs": [],
      "source": [
        "#Code cell 21\n",
        "#The Bokeh library we'll use to draw our map doesn't use normal latitude/longitude\n",
        "#coordinates, opting instead use Mercator coordinates.\n",
        "\n",
        "#This cell adapts code from a blog post by Craig Dickson showing a function for\n",
        "# converting from lat/long to Mercator that he attributes to Nadine Amersi-Belton:\n",
        "#https://towardsdatascience.com/creating-an-interactive-map-in-python-using-bokeh-and-pandas-f84414536a06\n",
        "\n",
        "# Define function to switch from lat/long to mercator coordinates\n",
        "def x_coord(x, y):\n",
        "\n",
        "    lat = x\n",
        "    lon = y\n",
        "\n",
        "    #Math. My son confirmed my dim memory that this was Trigonometry, and then looked at me pityingly.\n",
        "    r_major = 6378137.000\n",
        "    x = r_major * np.radians(lon)\n",
        "    scale = x/lon\n",
        "    y = 180.0/np.pi * np.log(np.tan(np.pi/4.0 +\n",
        "        lat * (np.pi/180.0)/2.0)) * scale\n",
        "    return (x, y)\n",
        "\n",
        "# Obtain list of mercator coordinates\n",
        "mercators = [x_coord(x, y) for x, y in regularized_bib_records['coords']]\n",
        "# Create mercator column in our dataframe\n",
        "regularized_bib_records['mercator'] = mercators\n",
        "# Split that column out into two separate columns: mercator_x and mercator_y\n",
        "regularized_bib_records[['mercator_x', 'mercator_y']] = regularized_bib_records['mercator'].apply(pd.Series)\n",
        "regularized_bib_records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4HUELnSQGnD"
      },
      "outputs": [],
      "source": [
        "#Code cell 22\n",
        "#Rather than being one monolithic library, Bokeh is set up as a collection\n",
        "#of more narrowly-focused modules. This means that Bokeh imports can\n",
        "#be pretty scary-looking.\n",
        "from bokeh.plotting import figure, show, curdoc\n",
        "from bokeh.tile_providers import get_provider\n",
        "from bokeh.io import output_notebook, reset_output\n",
        "from bokeh.layouts import layout, row, widgetbox\n",
        "from bokeh.models import Column, ColumnDataSource, CDSView, CustomJS, \\\n",
        "CustomJSFilter, HoverTool, RangeSlider, Row, Slider\n",
        "\n",
        "#Import the xyzservices library for choosing tiles other than those\n",
        "#provided by default by bokeh\n",
        "import xyzservices.providers as xyz\n",
        "\n",
        "#A command to make sure bokeh works in a Juyter/Colab notebook\n",
        "output_notebook()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zo4fmLdNXa-A"
      },
      "outputs": [],
      "source": [
        "#Code cell 23\n",
        "#We need to figure out the initial map view: what portion of the map do we need\n",
        "#to display to fit all of the places we want to show? This cell figures out the\n",
        "#minimum and maximum Mercator X and Y coordinates (i.e., the fartest points east, west,\n",
        "#south, and north).\n",
        "\n",
        "#We want the initial view to be a bit bigger than those coordinates, so the\n",
        "#pad_coords takes a Mercator coordinate, rounds it from a float to an integer\n",
        "#(i.e., gets rid of the decimal places) and then adds or subtracts 500000,\n",
        "#depending on whether the number is positive or negative.\n",
        "def pad_coords(mercator_float) :\n",
        "  rounded = round(mercator_float)\n",
        "  if rounded < 0 :\n",
        "    padded = rounded - 500000\n",
        "  else :\n",
        "    padded = rounded + 500000\n",
        "  return padded\n",
        "\n",
        "#Get the minimum and maximum values for our map view by getting the minimum and\n",
        "#maximum values from the mercator_x and mercator_y columns, then processing\n",
        "#those values using the pad_coords function.\n",
        "min_x = pad_coords(regularized_bib_records['mercator_x'].min())\n",
        "max_x = pad_coords(regularized_bib_records['mercator_x'].max())\n",
        "\n",
        "min_y = pad_coords(regularized_bib_records['mercator_y'].min())\n",
        "max_y = pad_coords(regularized_bib_records['mercator_y'].max())\n",
        "\n",
        "#Save the minima and maxima as variables to use in constructing our map view\n",
        "x_vals = (min_x, max_x)\n",
        "y_vals = (min_y, max_y)\n",
        "\n",
        "#We're going to have a slider to filter the map locations according to\n",
        "#publication year. This gets the minimum and maximumm pub_year values for\n",
        "#constructing that slider.\n",
        "earliest_date = regularized_bib_records['pub_year'].min()\n",
        "latest_date = regularized_bib_records['pub_year'].max()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xyzservices.lib import TileProvider\n",
        "davidrumsey = TileProvider(\n",
        "    name=\"David Rumsey\",\n",
        "    url=\"https://maps.georeferencer.com/georeferences/97a85ab4-5916-5335-a98d-4746ee461d95/2019-10-22T01:14:35.433817Z/map/{z}/{x}/{y}.png?key=SZKdmpxUvt19TydshGDy\",\n",
        "    attribution=\"(C) David Rumsey\",\n",
        "    )"
      ],
      "metadata": {
        "id": "jbdNd5dwyOcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOw3kmQSEBXp"
      },
      "outputs": [],
      "source": [
        "# Code cell 24\n",
        "\n",
        "#Let bokeh know the data to use\n",
        "source = ColumnDataSource(regularized_bib_records)\n",
        "\n",
        "#This is a bridge between Python and JavaScript: it says what to\n",
        "#do whenever the value of our slider changes, namely, announce that changed value.\n",
        "#The text in red after code= is actually JavaScript that we're wedging\n",
        "#in to what's otherwise Python scripting. (The three single quotes designate a\n",
        "#multiline string.)\n",
        "callback = CustomJS(args=dict(source=source), code='''\n",
        "    source.change.emit();\n",
        "''')\n",
        "\n",
        "#Define a slider to filter our records on the map by publication year\n",
        "slider = RangeSlider(start=earliest_date, end=latest_date, value=(earliest_date, latest_date),\n",
        "                           step=1, title=\"Publication Year\", max_width=500)\n",
        "\n",
        "#More Python to JavaScript bridging: whenver the value of the slider changes,\n",
        "#perform the callback function defined above, lines 11-13.\n",
        "slider.js_on_change('value', callback)\n",
        "\n",
        "#More Python to JavaScript bridging. Define a filter that will determine\n",
        "#which records bokeh will display on our map.\n",
        "pub_year_filter = CustomJSFilter(args=dict(source1=source, slider=slider), code='''\n",
        "const indices = [];\n",
        "\n",
        "// iterate through rows of data source and see if each satisfies some constraint\n",
        "for (let i = 0; i < source1.get_length(); i++){\n",
        "    if (source1.data['pub_year'][i] >= slider.value[0] && source1.data['pub_year'][i] <= slider.value[1]) {\n",
        "        indices.push(true);\n",
        "    } else {\n",
        "        indices.push(false);\n",
        "    }\n",
        "}\n",
        "return indices;\n",
        "''')\n",
        "\n",
        "#Define a view of our map that employs the pub_year_filter we just defined.\n",
        "view = CDSView(source=source, filters=[pub_year_filter])\n",
        "\n",
        "#Construct the actual map with some parameters: how wide it is, its intial viewport\n",
        "#(based on Mercator coordinates from code cell 20), its x- and y-axes, and title\n",
        "map = figure(plot_width=1000, x_range=x_vals, y_range=y_vals,\n",
        "           x_axis_type='mercator', y_axis_type='mercator', title='Bunyan\\'s Pilgrim\\'s Progress')\n",
        "#Add a blue circle to the map at each mercator_x/mercator_y pair in our data\n",
        "map.circle(x='mercator_x', y='mercator_y', size=10, fill_color=\"blue\",\n",
        "         fill_alpha=0.8, source=source, view=view)\n",
        "\n",
        "#Choose our map tiles. Lots of options available.\n",
        "# tile_provider = get_provider(xyz.Esri.WorldGrayCanvas)\n",
        "tile_provider = get_provider(davidrumsey)\n",
        "#Use those tiles for our map\n",
        "map.add_tile(tile_provider)\n",
        "\n",
        "#Make some information appear when we hover on one of our circles\n",
        "map.add_tools(HoverTool(\n",
        "    tooltips=[\n",
        "              ('ESTC', '@estc_num'),\n",
        "              ('Imprint', '@imprint')\n",
        "    ]))\n",
        "\n",
        "#Define a layout that includes our slider and map\n",
        "layout = Column(slider, map)\n",
        "#Show the layout we just defined\n",
        "show(layout)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}